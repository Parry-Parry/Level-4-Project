{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Model Training\n",
    "\n",
    "* Custom Tokenizer\n",
    "* GRU Encoder / Decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import sys\n",
    "\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "\n",
    "sys.path.append('D:\\PROJECT\\Level-4-Project')\n",
    "os.environ[\"TF_FORCE_GPU_ALLOW_GROWTH\"]=\"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from code2text.models.baseline.model import seq2seqTrain, MaskedLoss\n",
    "from code2text.helper.model import BatchLogs\n",
    "from code2text.helper.preprocess import tf_lower_and_split_punct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ijson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_text as text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.debugging.set_log_device_placement(True)\n",
    "tf.config.experimental.set_memory_growth(tf.config.experimental.list_physical_devices('GPU')[0], True)\n",
    "#tf.config.experimental.set_virtual_device_configuration(tf.config.experimental.list_physical_devices('GPU')[0],[tf.config.experimental.VirtualDeviceConfiguration(memory_limit=3072)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.run_functions_eagerly(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"D:\\PROJECT\\data\\CodeSearchNet\"\n",
    "langs = [\"java\", \"python\"]\n",
    "format = [\"train.jsonl\", \"test.jsonl\", \"valid.jsonl\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(path):\n",
    "    with open(path, encoding=\"UTF-8\") as json_file:\n",
    "        cursor = 0\n",
    "        code_set = []\n",
    "        string_set = []\n",
    "        lang_set = []\n",
    "        for _, line in enumerate(json_file):\n",
    "            code = None\n",
    "            string = None\n",
    "            line_as_file = io.StringIO(line)\n",
    "            json_parser = ijson.parse(line_as_file)\n",
    "\n",
    "            for prefix, _, value in json_parser:\n",
    "                if prefix == \"code\":  \n",
    "                    code = value\n",
    "                if prefix == \"docstring\":\n",
    "                    string = value\n",
    "                if prefix == \"language\":\n",
    "                    lang = value\n",
    "            if (code is not None and string is not None):\n",
    "                code_set.append(code)\n",
    "                string_set.append(string)\n",
    "                lang_set.append(lang)\n",
    "\n",
    "            cursor += len(line)\n",
    "    return pd.DataFrame(data={'code': code_set, 'docstring': string_set, 'language': lang_set})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing  java   train.jsonl ... \n",
      "Processing  java   test.jsonl ... \n",
      "Processing  java   valid.jsonl ... \n",
      "Processing  python   train.jsonl ... \n",
      "Processing  python   test.jsonl ... \n",
      "Processing  python   valid.jsonl ... \n"
     ]
    }
   ],
   "source": [
    "train = []\n",
    "test = []\n",
    "valid = []\n",
    "\n",
    "for lang in langs:\n",
    "    tmp = os.path.join(path, lang)\n",
    "    for file in format:\n",
    "        print(\"Processing \", lang, \" \", file, \"... \")\n",
    "        data = read_data(os.path.join(tmp, file))\n",
    "        if file == \"train.jsonl\":\n",
    "            train.append(data)\n",
    "        if file == \"test.jsonl\":\n",
    "            test.append(data)\n",
    "        if file == \"valid.jsonl\":\n",
    "            valid.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.concat(train)\n",
    "test = pd.concat(test)\n",
    "valid = pd.concat(valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([train, test, valid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.reset_index(inplace=True)\n",
    "train.to_json(\"D:\\PROJECT\\data\\CodeSearchNet\\Azure\\\\train.jsonl\", orient=\"records\", lines=True)\n",
    "test.reset_index(inplace=True)\n",
    "test.to_json(\"D:\\PROJECT\\data\\CodeSearchNet\\Azure\\\\test.jsonl\", orient=\"records\", lines=True)\n",
    "valid.reset_index(inplace=True)\n",
    "valid.to_json(\"D:\\PROJECT\\data\\CodeSearchNet\\Azure\\\\valid.jsonl\", orient=\"records\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.reset_index(inplace=True)\n",
    "data.to_json(\"D:\\PROJECT\\data\\CodeSearchNet\\Combine_clean\\data.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_json(\"D:\\PROJECT\\data\\CodeSearchNet\\Combine_clean\\data.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_json(\"D:\\PROJECT\\data\\CodeSearchNet\\Combine_clean\\\\train.json\")\n",
    "valid = pd.read_json(\"D:\\PROJECT\\data\\CodeSearchNet\\Combine_clean\\\\valid.json\")\n",
    "test = pd.read_json(\"D:\\PROJECT\\data\\CodeSearchNet\\Combine_clean\\\\test.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "buffer = 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = (\n",
    "    tf.data.Dataset.from_tensor_slices(\n",
    "        (\n",
    "            tf.cast(data[\"code\"].values, tf.string),\n",
    "            tf.cast(data[\"docstring\"].values, tf.string)\n",
    "        )\n",
    "    )\n",
    ").shuffle(buffer).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = (\n",
    "    tf.data.Dataset.from_tensor_slices(\n",
    "        (\n",
    "            tf.cast(train[\"code\"].values, tf.string),\n",
    "            tf.cast(train[\"docstring\"].values, tf.string)\n",
    "        )\n",
    "    )\n",
    ").shuffle(buffer).batch(batch_size, drop_remainder=True).cache().prefetch(tf.data.AUTOTUNE)\n",
    "test_set = (\n",
    "    tf.data.Dataset.from_tensor_slices(\n",
    "        (\n",
    "        tf.cast(test[\"code\"].values, tf.string),\n",
    "        tf.cast(test[\"docstring\"].values, tf.string)\n",
    "        )\n",
    "    )\n",
    ").shuffle(buffer).batch(batch_size, drop_remainder=True).cache().prefetch(tf.data.AUTOTUNE)\n",
    "valid_set = (\n",
    "    tf.data.Dataset.from_tensor_slices(\n",
    "        (\n",
    "        tf.cast(valid[\"code\"].values, tf.string),\n",
    "        tf.cast(valid[\"docstring\"].values, tf.string)\n",
    "        )  \n",
    "    )\n",
    ").shuffle(buffer).batch(batch_size, drop_remainder=True).cache().prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config & Build"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adapt Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = 30000\n",
    "input_processor = input_text_processor = tf.keras.layers.TextVectorization(\n",
    "    standardize=tf_lower_and_split_punct,\n",
    "    max_tokens=tokens)\n",
    "\n",
    "output_processor = tf.keras.layers.TextVectorization(\n",
    "    standardize=tf_lower_and_split_punct,\n",
    "    max_tokens=tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_processor.adapt(train[\"code\"])\n",
    "output_processor.adapt(train[\"docstring\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"D:\\PROJECT\\Level-4-Project\\data\\invocab.txt\", \"w\") as infile:\n",
    "    infile.write(\"\\n\".join(map(str, input_processor.get_vocabulary())))\n",
    "\n",
    "with open(\"D:\\PROJECT\\Level-4-Project\\data\\outvocab.txt\", \"w\") as outfile:\n",
    "    outfile.write(\"\\n\".join(map(str, output_processor.get_vocabulary())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_processor = input_text_processor = tf.keras.layers.TextVectorization(\n",
    "    standardize=tf_lower_and_split_punct,\n",
    "    vocabulary=\"D:\\PROJECT\\Level-4-Project\\data\\outvocab.txt\")\n",
    "\n",
    "output_processor = tf.keras.layers.TextVectorization(\n",
    "    standardize=tf_lower_and_split_punct,\n",
    "    vocabulary=\"D:\\PROJECT\\Level-4-Project\\data\\outvocab.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model = seq2seqTrain(112, 64, input_text_processor=input_processor,\n",
    "    output_text_processor=output_processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model.compile(\n",
    "    optimizer=tf.optimizers.Adam(learning_rate=0.0004),\n",
    "    loss=MaskedLoss(),\n",
    "    metrics=['acc', text.metrics.rouge_l]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_loss = BatchLogs('batch_loss')\n",
    "chkpt = tf.keras.callbacks.ModelCheckpoint(\n",
    "    \"D:\\PROJECT\\Level-4-Project\\notebooks\\training\\chkpt\\baseline\", monitor='loss', save_best_only=True, save_freq=1000\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Parry\\AppData\\Local\\Temp\\ipykernel_11296\\2871295278.py:1: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_gpu_available(\n",
    "    cuda_only=False,\n",
    "    min_cuda_compute_capability=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "  999/14190 [=>............................] - ETA: 16:18:16 - batch_loss: 5.7883WARNING:tensorflow:Can save best model only with loss available, skipping.\n",
      " 1999/14190 [===>..........................] - ETA: 14:53:02 - batch_loss: 5.4793WARNING:tensorflow:Can save best model only with loss available, skipping.\n",
      " 2050/14190 [===>..........................] - ETA: 14:46:15 - batch_loss: 5.4566"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Graph execution error:\n\nDetected at node 'while/decoder/attention/additive_attention/Sum' defined at (most recent call last):\n    File \"D:\\CONDA\\envs\\code2text\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"D:\\CONDA\\envs\\code2text\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"D:\\CONDA\\envs\\code2text\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"D:\\CONDA\\envs\\code2text\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n      app.start()\n    File \"D:\\CONDA\\envs\\code2text\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n      self.io_loop.start()\n    File \"D:\\CONDA\\envs\\code2text\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"D:\\CONDA\\envs\\code2text\\lib\\asyncio\\base_events.py\", line 596, in run_forever\n      self._run_once()\n    File \"D:\\CONDA\\envs\\code2text\\lib\\asyncio\\base_events.py\", line 1890, in _run_once\n      handle._run()\n    File \"D:\\CONDA\\envs\\code2text\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"D:\\CONDA\\envs\\code2text\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 461, in dispatch_queue\n      await self.process_one()\n    File \"D:\\CONDA\\envs\\code2text\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 450, in process_one\n      await dispatch(*args)\n    File \"D:\\CONDA\\envs\\code2text\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 357, in dispatch_shell\n      await result\n    File \"D:\\CONDA\\envs\\code2text\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 652, in execute_request\n      reply_content = await reply_content\n    File \"D:\\CONDA\\envs\\code2text\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 359, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"D:\\CONDA\\envs\\code2text\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 532, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"D:\\CONDA\\envs\\code2text\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2768, in run_cell\n      result = self._run_cell(\n    File \"D:\\CONDA\\envs\\code2text\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2814, in _run_cell\n      return runner(coro)\n    File \"D:\\CONDA\\envs\\code2text\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"D:\\CONDA\\envs\\code2text\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3012, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"D:\\CONDA\\envs\\code2text\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3191, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"D:\\CONDA\\envs\\code2text\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3251, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\Parry\\AppData\\Local\\Temp\\ipykernel_6380\\4110161981.py\", line 1, in <module>\n      history = train_model.fit(train_set, epochs=3, validation_data=valid_set, callbacks=[batch_loss, chkpt])\n    File \"D:\\CONDA\\envs\\code2text\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"D:\\CONDA\\envs\\code2text\\lib\\site-packages\\keras\\engine\\training.py\", line 1384, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"D:\\CONDA\\envs\\code2text\\lib\\site-packages\\keras\\engine\\training.py\", line 1021, in train_function\n      return step_function(self, iterator)\n    File \"D:\\CONDA\\envs\\code2text\\lib\\site-packages\\keras\\engine\\training.py\", line 1010, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"D:\\CONDA\\envs\\code2text\\lib\\site-packages\\keras\\engine\\training.py\", line 1000, in run_step\n      outputs = model.train_step(data)\n    File \"D:\\PROJECT\\Level-4-Project\\code2text\\models\\baseline\\model.py\", line 204, in train_step\n      return self._train_step(inputs)\n    File \"D:\\PROJECT\\Level-4-Project\\code2text\\models\\baseline\\model.py\", line 188, in _train_step\n      for t in tf.range(max_target_length-1):\n    File \"D:\\PROJECT\\Level-4-Project\\code2text\\models\\baseline\\model.py\", line 190, in _train_step\n      step_loss, dec_state = self._loop_step(new_tokens, input_mask,\n    File \"D:\\PROJECT\\Level-4-Project\\code2text\\models\\baseline\\model.py\", line 165, in _loop_step\n      dec_result, dec_state = self.decoder(decoder_input, state=dec_state)\n    File \"D:\\CONDA\\envs\\code2text\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"D:\\CONDA\\envs\\code2text\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"D:\\CONDA\\envs\\code2text\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"D:\\PROJECT\\Level-4-Project\\code2text\\models\\baseline\\model.py\", line 119, in call\n      context_vector, attention_weights = self.attention(\n    File \"D:\\CONDA\\envs\\code2text\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"D:\\CONDA\\envs\\code2text\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"D:\\CONDA\\envs\\code2text\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"D:\\PROJECT\\Level-4-Project\\code2text\\models\\baseline\\model.py\", line 52, in call\n      context_vector, attention_weights = self.attention(\n    File \"D:\\CONDA\\envs\\code2text\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"D:\\CONDA\\envs\\code2text\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"D:\\CONDA\\envs\\code2text\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"D:\\CONDA\\envs\\code2text\\lib\\site-packages\\keras\\layers\\dense_attention.py\", line 147, in call\n      scores = self._calculate_scores(query=q, key=k)\n    File \"D:\\CONDA\\envs\\code2text\\lib\\site-packages\\keras\\layers\\dense_attention.py\", line 500, in _calculate_scores\n      return tf.reduce_sum(\nNode: 'while/decoder/attention/additive_attention/Sum'\nDetected at node 'while/decoder/attention/additive_attention/Sum' defined at (most recent call last):\n    File \"D:\\CONDA\\envs\\code2text\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"D:\\CONDA\\envs\\code2text\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"D:\\CONDA\\envs\\code2text\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"D:\\CONDA\\envs\\code2text\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n      app.start()\n    File \"D:\\CONDA\\envs\\code2text\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n      self.io_loop.start()\n    File \"D:\\CONDA\\envs\\code2text\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"D:\\CONDA\\envs\\code2text\\lib\\asyncio\\base_events.py\", line 596, in run_forever\n      self._run_once()\n    File \"D:\\CONDA\\envs\\code2text\\lib\\asyncio\\base_events.py\", line 1890, in _run_once\n      handle._run()\n    File \"D:\\CONDA\\envs\\code2text\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"D:\\CONDA\\envs\\code2text\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 461, in dispatch_queue\n      await self.process_one()\n    File \"D:\\CONDA\\envs\\code2text\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 450, in process_one\n      await dispatch(*args)\n    File \"D:\\CONDA\\envs\\code2text\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 357, in dispatch_shell\n      await result\n    File \"D:\\CONDA\\envs\\code2text\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 652, in execute_request\n      reply_content = await reply_content\n    File \"D:\\CONDA\\envs\\code2text\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 359, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"D:\\CONDA\\envs\\code2text\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 532, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"D:\\CONDA\\envs\\code2text\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2768, in run_cell\n      result = self._run_cell(\n    File \"D:\\CONDA\\envs\\code2text\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2814, in _run_cell\n      return runner(coro)\n    File \"D:\\CONDA\\envs\\code2text\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"D:\\CONDA\\envs\\code2text\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3012, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"D:\\CONDA\\envs\\code2text\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3191, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"D:\\CONDA\\envs\\code2text\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3251, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\Parry\\AppData\\Local\\Temp\\ipykernel_6380\\4110161981.py\", line 1, in <module>\n      history = train_model.fit(train_set, epochs=3, validation_data=valid_set, callbacks=[batch_loss, chkpt])\n    File \"D:\\CONDA\\envs\\code2text\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"D:\\CONDA\\envs\\code2text\\lib\\site-packages\\keras\\engine\\training.py\", line 1384, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"D:\\CONDA\\envs\\code2text\\lib\\site-packages\\keras\\engine\\training.py\", line 1021, in train_function\n      return step_function(self, iterator)\n    File \"D:\\CONDA\\envs\\code2text\\lib\\site-packages\\keras\\engine\\training.py\", line 1010, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"D:\\CONDA\\envs\\code2text\\lib\\site-packages\\keras\\engine\\training.py\", line 1000, in run_step\n      outputs = model.train_step(data)\n    File \"D:\\PROJECT\\Level-4-Project\\code2text\\models\\baseline\\model.py\", line 204, in train_step\n      return self._train_step(inputs)\n    File \"D:\\PROJECT\\Level-4-Project\\code2text\\models\\baseline\\model.py\", line 188, in _train_step\n      for t in tf.range(max_target_length-1):\n    File \"D:\\PROJECT\\Level-4-Project\\code2text\\models\\baseline\\model.py\", line 190, in _train_step\n      step_loss, dec_state = self._loop_step(new_tokens, input_mask,\n    File \"D:\\PROJECT\\Level-4-Project\\code2text\\models\\baseline\\model.py\", line 165, in _loop_step\n      dec_result, dec_state = self.decoder(decoder_input, state=dec_state)\n    File \"D:\\CONDA\\envs\\code2text\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"D:\\CONDA\\envs\\code2text\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"D:\\CONDA\\envs\\code2text\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"D:\\PROJECT\\Level-4-Project\\code2text\\models\\baseline\\model.py\", line 119, in call\n      context_vector, attention_weights = self.attention(\n    File \"D:\\CONDA\\envs\\code2text\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"D:\\CONDA\\envs\\code2text\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"D:\\CONDA\\envs\\code2text\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"D:\\PROJECT\\Level-4-Project\\code2text\\models\\baseline\\model.py\", line 52, in call\n      context_vector, attention_weights = self.attention(\n    File \"D:\\CONDA\\envs\\code2text\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"D:\\CONDA\\envs\\code2text\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"D:\\CONDA\\envs\\code2text\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"D:\\CONDA\\envs\\code2text\\lib\\site-packages\\keras\\layers\\dense_attention.py\", line 147, in call\n      scores = self._calculate_scores(query=q, key=k)\n    File \"D:\\CONDA\\envs\\code2text\\lib\\site-packages\\keras\\layers\\dense_attention.py\", line 500, in _calculate_scores\n      return tf.reduce_sum(\nNode: 'while/decoder/attention/additive_attention/Sum'\n2 root error(s) found.\n  (0) RESOURCE_EXHAUSTED:  OOM when allocating tensor with shape[14464] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node while/decoder/attention/additive_attention/Sum}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n\t [[StatefulPartitionedCall/while/LoopCond/_276/_334]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n  (1) RESOURCE_EXHAUSTED:  OOM when allocating tensor with shape[14464] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node while/decoder/attention/additive_attention/Sum}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_8654]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32md:\\PROJECT\\Level-4-Project\\notebooks\\training\\baseline.ipynb Cell 36'\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/PROJECT/Level-4-Project/notebooks/training/baseline.ipynb#ch0000035?line=0'>1</a>\u001b[0m history \u001b[39m=\u001b[39m train_model\u001b[39m.\u001b[39;49mfit(train_set, epochs\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m, validation_data\u001b[39m=\u001b[39;49mvalid_set, callbacks\u001b[39m=\u001b[39;49m[batch_loss, chkpt])\n",
      "File \u001b[1;32mD:\\CONDA\\envs\\code2text\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     <a href='file:///d%3A/CONDA/envs/code2text/lib/site-packages/keras/utils/traceback_utils.py?line=64'>65</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     <a href='file:///d%3A/CONDA/envs/code2text/lib/site-packages/keras/utils/traceback_utils.py?line=65'>66</a>\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m---> <a href='file:///d%3A/CONDA/envs/code2text/lib/site-packages/keras/utils/traceback_utils.py?line=66'>67</a>\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     <a href='file:///d%3A/CONDA/envs/code2text/lib/site-packages/keras/utils/traceback_utils.py?line=67'>68</a>\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     <a href='file:///d%3A/CONDA/envs/code2text/lib/site-packages/keras/utils/traceback_utils.py?line=68'>69</a>\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mD:\\CONDA\\envs\\code2text\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     <a href='file:///d%3A/CONDA/envs/code2text/lib/site-packages/tensorflow/python/eager/execute.py?line=51'>52</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     <a href='file:///d%3A/CONDA/envs/code2text/lib/site-packages/tensorflow/python/eager/execute.py?line=52'>53</a>\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> <a href='file:///d%3A/CONDA/envs/code2text/lib/site-packages/tensorflow/python/eager/execute.py?line=53'>54</a>\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     <a href='file:///d%3A/CONDA/envs/code2text/lib/site-packages/tensorflow/python/eager/execute.py?line=54'>55</a>\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     <a href='file:///d%3A/CONDA/envs/code2text/lib/site-packages/tensorflow/python/eager/execute.py?line=55'>56</a>\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     <a href='file:///d%3A/CONDA/envs/code2text/lib/site-packages/tensorflow/python/eager/execute.py?line=56'>57</a>\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node 'while/decoder/attention/additive_attention/Sum' defined at (most recent call last):\n    File \"D:\\CONDA\\envs\\code2text\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"D:\\CONDA\\envs\\code2text\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"D:\\CONDA\\envs\\code2text\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"D:\\CONDA\\envs\\code2text\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n      app.start()\n    File \"D:\\CONDA\\envs\\code2text\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n      self.io_loop.start()\n    File \"D:\\CONDA\\envs\\code2text\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"D:\\CONDA\\envs\\code2text\\lib\\asyncio\\base_events.py\", line 596, in run_forever\n      self._run_once()\n    File \"D:\\CONDA\\envs\\code2text\\lib\\asyncio\\base_events.py\", line 1890, in _run_once\n      handle._run()\n    File \"D:\\CONDA\\envs\\code2text\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"D:\\CONDA\\envs\\code2text\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 461, in dispatch_queue\n      await self.process_one()\n    File \"D:\\CONDA\\envs\\code2text\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 450, in process_one\n      await dispatch(*args)\n    File \"D:\\CONDA\\envs\\code2text\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 357, in dispatch_shell\n      await result\n    File \"D:\\CONDA\\envs\\code2text\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 652, in execute_request\n      reply_content = await reply_content\n    File \"D:\\CONDA\\envs\\code2text\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 359, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"D:\\CONDA\\envs\\code2text\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 532, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"D:\\CONDA\\envs\\code2text\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2768, in run_cell\n      result = self._run_cell(\n    File \"D:\\CONDA\\envs\\code2text\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2814, in _run_cell\n      return runner(coro)\n    File \"D:\\CONDA\\envs\\code2text\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"D:\\CONDA\\envs\\code2text\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3012, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"D:\\CONDA\\envs\\code2text\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3191, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"D:\\CONDA\\envs\\code2text\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3251, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\Parry\\AppData\\Local\\Temp\\ipykernel_6380\\4110161981.py\", line 1, in <module>\n      history = train_model.fit(train_set, epochs=3, validation_data=valid_set, callbacks=[batch_loss, chkpt])\n    File \"D:\\CONDA\\envs\\code2text\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"D:\\CONDA\\envs\\code2text\\lib\\site-packages\\keras\\engine\\training.py\", line 1384, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"D:\\CONDA\\envs\\code2text\\lib\\site-packages\\keras\\engine\\training.py\", line 1021, in train_function\n      return step_function(self, iterator)\n    File \"D:\\CONDA\\envs\\code2text\\lib\\site-packages\\keras\\engine\\training.py\", line 1010, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"D:\\CONDA\\envs\\code2text\\lib\\site-packages\\keras\\engine\\training.py\", line 1000, in run_step\n      outputs = model.train_step(data)\n    File \"D:\\PROJECT\\Level-4-Project\\code2text\\models\\baseline\\model.py\", line 204, in train_step\n      return self._train_step(inputs)\n    File \"D:\\PROJECT\\Level-4-Project\\code2text\\models\\baseline\\model.py\", line 188, in _train_step\n      for t in tf.range(max_target_length-1):\n    File \"D:\\PROJECT\\Level-4-Project\\code2text\\models\\baseline\\model.py\", line 190, in _train_step\n      step_loss, dec_state = self._loop_step(new_tokens, input_mask,\n    File \"D:\\PROJECT\\Level-4-Project\\code2text\\models\\baseline\\model.py\", line 165, in _loop_step\n      dec_result, dec_state = self.decoder(decoder_input, state=dec_state)\n    File \"D:\\CONDA\\envs\\code2text\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"D:\\CONDA\\envs\\code2text\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"D:\\CONDA\\envs\\code2text\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"D:\\PROJECT\\Level-4-Project\\code2text\\models\\baseline\\model.py\", line 119, in call\n      context_vector, attention_weights = self.attention(\n    File \"D:\\CONDA\\envs\\code2text\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"D:\\CONDA\\envs\\code2text\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"D:\\CONDA\\envs\\code2text\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"D:\\PROJECT\\Level-4-Project\\code2text\\models\\baseline\\model.py\", line 52, in call\n      context_vector, attention_weights = self.attention(\n    File \"D:\\CONDA\\envs\\code2text\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"D:\\CONDA\\envs\\code2text\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"D:\\CONDA\\envs\\code2text\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"D:\\CONDA\\envs\\code2text\\lib\\site-packages\\keras\\layers\\dense_attention.py\", line 147, in call\n      scores = self._calculate_scores(query=q, key=k)\n    File \"D:\\CONDA\\envs\\code2text\\lib\\site-packages\\keras\\layers\\dense_attention.py\", line 500, in _calculate_scores\n      return tf.reduce_sum(\nNode: 'while/decoder/attention/additive_attention/Sum'\nDetected at node 'while/decoder/attention/additive_attention/Sum' defined at (most recent call last):\n    File \"D:\\CONDA\\envs\\code2text\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"D:\\CONDA\\envs\\code2text\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"D:\\CONDA\\envs\\code2text\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"D:\\CONDA\\envs\\code2text\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n      app.start()\n    File \"D:\\CONDA\\envs\\code2text\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n      self.io_loop.start()\n    File \"D:\\CONDA\\envs\\code2text\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"D:\\CONDA\\envs\\code2text\\lib\\asyncio\\base_events.py\", line 596, in run_forever\n      self._run_once()\n    File \"D:\\CONDA\\envs\\code2text\\lib\\asyncio\\base_events.py\", line 1890, in _run_once\n      handle._run()\n    File \"D:\\CONDA\\envs\\code2text\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"D:\\CONDA\\envs\\code2text\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 461, in dispatch_queue\n      await self.process_one()\n    File \"D:\\CONDA\\envs\\code2text\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 450, in process_one\n      await dispatch(*args)\n    File \"D:\\CONDA\\envs\\code2text\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 357, in dispatch_shell\n      await result\n    File \"D:\\CONDA\\envs\\code2text\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 652, in execute_request\n      reply_content = await reply_content\n    File \"D:\\CONDA\\envs\\code2text\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 359, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"D:\\CONDA\\envs\\code2text\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 532, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"D:\\CONDA\\envs\\code2text\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2768, in run_cell\n      result = self._run_cell(\n    File \"D:\\CONDA\\envs\\code2text\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2814, in _run_cell\n      return runner(coro)\n    File \"D:\\CONDA\\envs\\code2text\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"D:\\CONDA\\envs\\code2text\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3012, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"D:\\CONDA\\envs\\code2text\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3191, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"D:\\CONDA\\envs\\code2text\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3251, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\Parry\\AppData\\Local\\Temp\\ipykernel_6380\\4110161981.py\", line 1, in <module>\n      history = train_model.fit(train_set, epochs=3, validation_data=valid_set, callbacks=[batch_loss, chkpt])\n    File \"D:\\CONDA\\envs\\code2text\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"D:\\CONDA\\envs\\code2text\\lib\\site-packages\\keras\\engine\\training.py\", line 1384, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"D:\\CONDA\\envs\\code2text\\lib\\site-packages\\keras\\engine\\training.py\", line 1021, in train_function\n      return step_function(self, iterator)\n    File \"D:\\CONDA\\envs\\code2text\\lib\\site-packages\\keras\\engine\\training.py\", line 1010, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"D:\\CONDA\\envs\\code2text\\lib\\site-packages\\keras\\engine\\training.py\", line 1000, in run_step\n      outputs = model.train_step(data)\n    File \"D:\\PROJECT\\Level-4-Project\\code2text\\models\\baseline\\model.py\", line 204, in train_step\n      return self._train_step(inputs)\n    File \"D:\\PROJECT\\Level-4-Project\\code2text\\models\\baseline\\model.py\", line 188, in _train_step\n      for t in tf.range(max_target_length-1):\n    File \"D:\\PROJECT\\Level-4-Project\\code2text\\models\\baseline\\model.py\", line 190, in _train_step\n      step_loss, dec_state = self._loop_step(new_tokens, input_mask,\n    File \"D:\\PROJECT\\Level-4-Project\\code2text\\models\\baseline\\model.py\", line 165, in _loop_step\n      dec_result, dec_state = self.decoder(decoder_input, state=dec_state)\n    File \"D:\\CONDA\\envs\\code2text\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"D:\\CONDA\\envs\\code2text\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"D:\\CONDA\\envs\\code2text\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"D:\\PROJECT\\Level-4-Project\\code2text\\models\\baseline\\model.py\", line 119, in call\n      context_vector, attention_weights = self.attention(\n    File \"D:\\CONDA\\envs\\code2text\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"D:\\CONDA\\envs\\code2text\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"D:\\CONDA\\envs\\code2text\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"D:\\PROJECT\\Level-4-Project\\code2text\\models\\baseline\\model.py\", line 52, in call\n      context_vector, attention_weights = self.attention(\n    File \"D:\\CONDA\\envs\\code2text\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"D:\\CONDA\\envs\\code2text\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"D:\\CONDA\\envs\\code2text\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"D:\\CONDA\\envs\\code2text\\lib\\site-packages\\keras\\layers\\dense_attention.py\", line 147, in call\n      scores = self._calculate_scores(query=q, key=k)\n    File \"D:\\CONDA\\envs\\code2text\\lib\\site-packages\\keras\\layers\\dense_attention.py\", line 500, in _calculate_scores\n      return tf.reduce_sum(\nNode: 'while/decoder/attention/additive_attention/Sum'\n2 root error(s) found.\n  (0) RESOURCE_EXHAUSTED:  OOM when allocating tensor with shape[14464] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node while/decoder/attention/additive_attention/Sum}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n\t [[StatefulPartitionedCall/while/LoopCond/_276/_334]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n  (1) RESOURCE_EXHAUSTED:  OOM when allocating tensor with shape[14464] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node while/decoder/attention/additive_attention/Sum}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_8654]"
     ]
    }
   ],
   "source": [
    "history = train_model.fit(train_set, epochs=3, validation_data=valid_set, callbacks=[batch_loss, chkpt])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation & Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2db524e06e9f5f4ffedc911c917cb75e12dbc923643829bf417064a77eb14d37"
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
