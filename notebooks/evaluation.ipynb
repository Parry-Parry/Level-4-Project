{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of Seq2Seq Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, LogitsProcessorList, MinLengthLogitsProcessor, TopKLogitsWarper, TemperatureLogitsWarper, BeamSearchScorer\n",
    "import torch\n",
    "import datasets \n",
    "import pickle \n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup & Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/codebert-base\")\n",
    "\n",
    "def tokenize_function(set):\n",
    "    inputs = tokenizer(set[\"code\"], max_length=512, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "       labels = tokenizer(set[\"docstring\"], max_length=512, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "    inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Parry\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Parry\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\Parry\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "bleu = datasets.load_metric('sacrebleu')\n",
    "rouge = datasets.load_metric('rouge')\n",
    "meteor = datasets.load_metric('meteor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "class testWrapper():\n",
    "    def __init__(self, model):\n",
    "        self.model = model.cuda()\n",
    "\n",
    "        self.beam_scorer = BeamSearchScorer(\n",
    "        batch_size=4,\n",
    "        max_length=self.model.config.max_length,\n",
    "        num_beams=4,\n",
    "        device=self.model.device,\n",
    "        )\n",
    "        \n",
    "        self.logits_processor = LogitsProcessorList(\n",
    "        [MinLengthLogitsProcessor(5, eos_token_id=self.model.config.eos_token_id)]\n",
    "        )\n",
    "\n",
    "        self.logits_warper = LogitsProcessorList(\n",
    "            [\n",
    "            TopKLogitsWarper(50),\n",
    "            TemperatureLogitsWarper(0.7),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        input_ids = torch.ones((4, 1), device=self.model.device, dtype=torch.long)\n",
    "        self.input_ids = input_ids * self.model.config.decoder_start_token_id\n",
    "    \n",
    "    def generate_string(self, batch):\n",
    "        inputs = tokenizer(batch[\"code\"], padding=\"max_length\", truncation=True, max_length=512, return_tensors=\"pt\")\n",
    "        input_ids = inputs.input_ids.cuda()\n",
    "        attention_mask = inputs.attention_mask.cuda()\n",
    "        outputs = self.model.generate(input_ids, attention_mask=attention_mask)\n",
    "        output_str = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "        batch[\"pred_string\"] = output_str\n",
    "        return batch\n",
    "    \n",
    "    def generate_per_string(self, batch):\n",
    "        inputs = tokenizer(batch[\"code\"], padding=\"max_length\", truncation=True, max_length=512, return_tensors=\"pt\")\n",
    "        input_ids = inputs.input_ids.cuda()\n",
    "        attention_mask = inputs.attention_mask.cuda()\n",
    "        outputs = self.model.generate(input_ids, attention_mask=attention_mask)\n",
    "        output_str = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "        batch[\"pred_string\"] = output_str\n",
    "\n",
    "        predictions = output_str\n",
    "        references = [batch[\"docstring\"]]\n",
    "\n",
    "        rouge_output = rouge.compute(predictions=predictions, references=references, rouge_types=[\"rouge2\"])[\"rouge2\"].mid\n",
    "        bleu_output = bleu.compute(predictions=predictions, references=[[ref] for ref in references])\n",
    "        meteor_output = meteor.compute(predictions=predictions, references=references)\n",
    "\n",
    "        batch[\"rouge2_precision\"] = round(rouge_output.precision, 4)\n",
    "        batch[\"rouge2_recall\"] = round(rouge_output.recall, 4)\n",
    "        batch[\"rouge2_fmeasure\"] = round(rouge_output.fmeasure, 4)\n",
    "        batch[\"bleu_score\"] = bleu_output[\"score\"]\n",
    "        batch[\"meteor_score\"] = meteor_output[\"meteor\"]\n",
    "        \n",
    "        return batch\n",
    "\n",
    "    def test_gen(self, batch):\n",
    "        encoder_input_ids = tokenizer(batch['code'], padding=\"max_length\", truncation=True, max_length=512, return_tensors=\"pt\").input_ids\n",
    "        model_kwargs = {\n",
    "        \"encoder_outputs\": self.model.get_encoder()(\n",
    "            encoder_input_ids.repeat_interleave(4, dim=0), return_dict=True\n",
    "            )\n",
    "        }   \n",
    "        outputs = self.model.beam_sample(\n",
    "        self.input_ids, self.beam_scorer, logits_processor=self.logits_processor, logits_warper=self.logits_warper, **model_kwargs\n",
    "        )\n",
    "        batch['pred_string'] = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_compute(results):\n",
    "    predictions=results[\"pred_string\"] \n",
    "    references=results[\"docstring\"]\n",
    "\n",
    "    rouge_output = rouge.compute(predictions=predictions, references=references, rouge_types=[\"rouge2\"])[\"rouge2\"].mid\n",
    "    bleu_output = bleu.compute(predictions=predictions, references=[[ref] for ref in references])\n",
    "    meteor_output = meteor.compute(predictions=predictions, references=references)\n",
    "\n",
    "    return {\n",
    "        \"rouge2_precision\": round(rouge_output.precision, 4),\n",
    "        \"rouge2_recall\": round(rouge_output.recall, 4),\n",
    "        \"rouge2_fmeasure\": round(rouge_output.fmeasure, 4),\n",
    "        \"bleu_score\" : bleu_output[\"score\"],\n",
    "        \"meteor_score\" : meteor_output[\"meteor\"]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelSetup(path):\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(path)\n",
    "\n",
    "    model.config.decoder_start_token_id = tokenizer.cls_token_id\n",
    "    model.config.eos_token_id = tokenizer.sep_token_id\n",
    "    model.config.pad_token_id = tokenizer.pad_token_id\n",
    "    model.config.vocab_size = model.config.encoder.vocab_size\n",
    "    model.config.num_beams = 4\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ttest(delta, N):\n",
    "    deg_free = N - 1\n",
    "    d_sq = delta ** 2\n",
    "    t = (np.sum(delta)/N) / np.sqrt((np.sum(d_sq) - ((np.sum(delta)**2) / N)) / ((N - 1) * N))\n",
    "    return t, p\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## No Augmentation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-3f4bdb1ea0486ba6\n",
      "Reusing dataset json (C:\\Users\\Parry\\.cache\\huggingface\\datasets\\json\\default-3f4bdb1ea0486ba6\\0.0.0\\ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b)\n",
      "100%|██████████| 1/1 [00:00<00:00, 199.97it/s]\n"
     ]
    }
   ],
   "source": [
    "test_set = datasets.load_dataset('json', data_files=\"D:\\\\PROJECT\\\\data\\\\CodeSearchNet\\\\py_clean\\\\test.jsonl\")[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_test = test_set.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>docstring</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>def sina_xml_to_url_list(xml_data):\\n    \"\"\"st...</td>\n",
       "      <td>str-&gt;list\\n    Convert XML to URL List.\\n    F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>def dailymotion_download(url, output_dir='.', ...</td>\n",
       "      <td>Downloads Dailymotion videos by URL.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>def sina_download(url, output_dir='.', merge=T...</td>\n",
       "      <td>Downloads Sina videos by URL.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>def sprint(text, *colors):\\n    \"\"\"Format text...</td>\n",
       "      <td>Format text with color or other effects into A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>def print_log(text, *colors):\\n    \"\"\"Print a ...</td>\n",
       "      <td>Print a log message to standard error.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14913</th>\n",
       "      <td>def from_grayscale(im, channels_on=(True, True...</td>\n",
       "      <td>Return a canvas from a grayscale image.\\n\\n   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14914</th>\n",
       "      <td>def get_uuid(length=32, version=1):\\n    \"\"\"\\n...</td>\n",
       "      <td>Returns a unique ID of a given length.\\n    Us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14915</th>\n",
       "      <td>def get_unique_key_from_get(get_dict):\\n    \"\"...</td>\n",
       "      <td>Build a unique key from get data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14916</th>\n",
       "      <td>def get_domain(url):\\n    \"\"\" Returns domain n...</td>\n",
       "      <td>Returns domain name portion of a URL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14917</th>\n",
       "      <td>def get_url_args(url):\\n    \"\"\" Returns a dict...</td>\n",
       "      <td>Returns a dictionary from a URL params</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14918 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    code  \\\n",
       "0      def sina_xml_to_url_list(xml_data):\\n    \"\"\"st...   \n",
       "1      def dailymotion_download(url, output_dir='.', ...   \n",
       "2      def sina_download(url, output_dir='.', merge=T...   \n",
       "3      def sprint(text, *colors):\\n    \"\"\"Format text...   \n",
       "4      def print_log(text, *colors):\\n    \"\"\"Print a ...   \n",
       "...                                                  ...   \n",
       "14913  def from_grayscale(im, channels_on=(True, True...   \n",
       "14914  def get_uuid(length=32, version=1):\\n    \"\"\"\\n...   \n",
       "14915  def get_unique_key_from_get(get_dict):\\n    \"\"...   \n",
       "14916  def get_domain(url):\\n    \"\"\" Returns domain n...   \n",
       "14917  def get_url_args(url):\\n    \"\"\" Returns a dict...   \n",
       "\n",
       "                                               docstring  \n",
       "0      str->list\\n    Convert XML to URL List.\\n    F...  \n",
       "1                   Downloads Dailymotion videos by URL.  \n",
       "2                          Downloads Sina videos by URL.  \n",
       "3      Format text with color or other effects into A...  \n",
       "4                 Print a log message to standard error.  \n",
       "...                                                  ...  \n",
       "14913  Return a canvas from a grayscale image.\\n\\n   ...  \n",
       "14914  Returns a unique ID of a given length.\\n    Us...  \n",
       "14915                   Build a unique key from get data  \n",
       "14916               Returns domain name portion of a URL  \n",
       "14917             Returns a dictionary from a URL params  \n",
       "\n",
       "[14918 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"D:\\\\PROJECT\\\\out\\\\original\\\\small\\\\results.pkl\", 'rb') as f:\n",
    "    frame = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge2_precision': 0.99,\n",
       " 'rouge2_recall': 0.5708,\n",
       " 'rouge2_fmeasure': 0.6429,\n",
       " 'bleu_score': 1.1199619518003372,\n",
       " 'meteor_score': 0.5586790863025023}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_path = \"D:\\PROJECT\\out\\original\\small\\model_out\"\n",
    "medium_path = \"D:\\PROJECT\\out\\original\\medium\\model_out\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_model = modelSetup(small_path)\n",
    "medium_model = modelSetup(medium_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_tester = testWrapper(small_model)\n",
    "medium_tester = testWrapper(medium_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#small_per_res = test_set.map(small_tester.generate_string, batched=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1865/1865 [34:59<00:00,  1.13s/ba]\n"
     ]
    }
   ],
   "source": [
    "medium_res = test_set.map(medium_tester.generate_string, batched=True, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "medium_per_scores = eval_compute(medium_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"D:\\\\PROJECT\\\\out\\\\original\\\\medium\\\\per_scores.pkl\", 'wb') as f:\n",
    "    pickle.dump(medium_per_scores, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14918/14918 [1:38:23<00:00,  2.53ex/s]\n"
     ]
    }
   ],
   "source": [
    "medium_per_res = test_set.map(medium_tester.generate_per_string, batched=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14918/14918 [1:09:31<00:00,  3.58ex/s]\n"
     ]
    }
   ],
   "source": [
    "small_per_res = test_set.map(small_tester.generate_per_string, batched=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"D:\\\\PROJECT\\\\out\\\\original\\\\small\\\\per_res.pkl\", 'wb') as f:\n",
    "    pickle.dump(small_per_res, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"D:\\\\PROJECT\\\\out\\\\original\\\\medium\\\\per_res.pkl\", 'wb') as f:\n",
    "    pickle.dump(medium_per_res, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nsmall_per_scores = eval_compute(small_res)\\nmedium_per_scores = eval_compute(medium_res)\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "small_per_scores = eval_compute(small_res)\n",
    "medium_per_scores = eval_compute(medium_res)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#medium_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#small_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The test function to be used for training.\\n\\n    Args:\\n ']\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer([str('import tensorflow as tf mnist = tf.keras.datasets.mnist (x_train, y_train),(x_test, y_test) = mnist.load_data() x_train, x_test = x_train / 255.0, x_test / 255.0')], padding=\"max_length\", truncation=True, max_length=512, return_tensors=\"pt\")\n",
    "input_ids = inputs.input_ids.cuda()\n",
    "attention_mask = inputs.attention_mask.cuda()\n",
    "outputs = medium_model.generate(input_ids, attention_mask=attention_mask)\n",
    "output_str = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "print(output_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"D:\\\\PROJECT\\\\out\\\\aug\\\\small\\\\results.pkl\", 'rb') as f:\n",
    "    frame = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge2_precision': 0.9666,\n",
       " 'rouge2_recall': 0.5221,\n",
       " 'rouge2_fmeasure': 0.5949,\n",
       " 'bleu_score': 1.0519508068544727,\n",
       " 'meteor_score': 0.5069636934626205}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_aug_path = \"D:\\\\PROJECT\\\\out\\\\aug\\small\\\\model_out\"\n",
    "medium_aug_path = \"D:\\\\PROJECT\\\\out\\\\aug\\medium\\\\model_out\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_aug_model = modelSetup(small_aug_path)\n",
    "medium_aug_model = modelSetup(medium_aug_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\CONDA\\envs\\build\\lib\\site-packages\\transformers\\generation_beam_search.py:196: UserWarning: Passing `max_length` to BeamSearchScorer is deprecated and has no effect. `max_length` should be passed directly to `beam_search(...)`, `beam_sample(...)`, or `group_beam_search(...)`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "small_aug_tester = testWrapper(small_aug_model)\n",
    "medium_aug_tester = testWrapper(medium_aug_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1865/1865 [37:15<00:00,  1.20s/ba]\n",
      "100%|██████████| 1865/1865 [18:04<00:00,  1.72ba/s]\n"
     ]
    }
   ],
   "source": [
    "medium_aug_res = test_set.map(medium_aug_tester.generate_string, batched=True, batch_size=8)\n",
    "small_aug_res = test_set.map(small_aug_tester.generate_string, batched=True, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "medium_aug_scores = eval_compute(medium_aug_res)\n",
    "small_aug_scores = eval_compute(small_aug_res) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge2_precision': 0.9386,\n",
       " 'rouge2_recall': 0.5736,\n",
       " 'rouge2_fmeasure': 0.607,\n",
       " 'bleu_score': 1.4974138333701776,\n",
       " 'meteor_score': 0.5430670378070557}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medium_aug_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge2_precision': 0.9335,\n",
       " 'rouge2_recall': 0.5708,\n",
       " 'rouge2_fmeasure': 0.6035,\n",
       " 'bleu_score': 1.489514462281551,\n",
       " 'meteor_score': 0.5415090320766118}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_aug_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "del medium_aug_scores\n",
    "del small_aug_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'function'=<function testWrapper.generate_per_string at 0x0000027ECD8CD310> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n",
      "100%|██████████| 14918/14918 [1:51:55<00:00,  2.22ex/s]\n",
      "100%|██████████| 14918/14918 [1:11:48<00:00,  3.46ex/s]\n"
     ]
    }
   ],
   "source": [
    "medium_aug_per_res = test_set.map(medium_aug_tester.generate_per_string, batched=False)\n",
    "with open(\"D:\\\\PROJECT\\\\out\\\\aug\\\\medium\\\\per_sentence_res.pkl\", 'wb') as f:\n",
    "    pickle.dump(medium_aug_per_res, f)\n",
    "small_aug_per_res = test_set.map(small_aug_tester.generate_per_string, batched=False)\n",
    "with open(\"D:\\\\PROJECT\\\\out\\\\aug\\\\small\\\\per_sentence_res.pkl\", 'wb') as f:\n",
    "    pickle.dump(small_aug_per_res, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "043b8ec81c094910c2b30aa6da4b87ee4064e49c6c2745b34a15c1b8c91b4ed0"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('build')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
